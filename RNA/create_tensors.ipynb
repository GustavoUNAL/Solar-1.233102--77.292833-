{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚úÖ Tensor de entrada  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([364, 288, 3])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json \n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# Obtener fechas √∫nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d√≠a\n",
    "tensors_dias = []\n",
    "# Diccionario para mapear fechas a √≠ndices en tensors_dias\n",
    "fechas_indices = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast.loc[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV.loc[df_SFV['Date'] == fecha]\n",
    "\n",
    "    # Verificar que el d√≠a tiene 288 registros\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        # Procesamiento normal...\n",
    "        # Resetear y ordenar por hora\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        # Crear DataFrame para el d√≠a actual\n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci√≥n_fotovoltaica_SFV': row_day_fronius['Producci√≥n_fotovoltaica_SFV'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "        })\n",
    "    \n",
    "        # Normalizar los datos\n",
    "        df_dia[['GHI', 'Producci√≥n_fotovoltaica_SFV', 'clearsky_ghi', 'cloud_opacity', 'air_temp']] = scaler.fit_transform(df_dia[['GHI', 'Producci√≥n_fotovoltaica_SFV', 'clearsky_ghi', 'cloud_opacity', 'air_temp']])\n",
    "    \n",
    "        # Convertir a tensor y cambiar forma\n",
    "        ghi_tensor = torch.tensor(df_dia['GHI'].values).view(-1, 1)\n",
    "        air_temp_tensor = torch.tensor(df_dia['air_temp'].values).view(-1, 1)\n",
    "        cloud_opacity_tensor = torch.tensor(df_dia['cloud_opacity'].values).view(-1, 1)\n",
    "    \n",
    "        # Concatenar y cambiar forma a [1, 288, 3]\n",
    "        dia_tensor = torch.cat((ghi_tensor, air_temp_tensor, cloud_opacity_tensor), dim=1).unsqueeze(0)\n",
    "    \n",
    "        # Agregar el tensor del d√≠a a la lista\n",
    "        tensors_dias.append(dia_tensor)\n",
    "        # Agregar la fecha al diccionario\n",
    "        fechas_indices[fecha] = len(tensors_dias) - 1\n",
    "\n",
    "# Verificar si hay d√≠as para concatenar\n",
    "if tensors_dias:\n",
    "    # Concatenar todos los tensores de d√≠as en un tensor [n, 288, 3]\n",
    "    tensor_final = torch.cat(tensors_dias, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, 3])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('../RNA/data_training/input_tensor.npy', tensor_final)\n",
    "    with open('../RNA/data_training/indice_fechas_input.json', 'w') as fp:\n",
    "        json.dump(fechas_indices, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚úÖ Tensor SFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([364, 288, 1])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# Obtener fechas √∫nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d√≠a de la producci√≥n fotovoltaica\n",
    "tensors_SFV = []\n",
    "# Diccionario para mapear fechas a √≠ndices en tensors_SFV\n",
    "indice_fechas_SFV = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast.loc[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV.loc[df_SFV['Date'] == fecha]\n",
    "\n",
    "    # Verificar que el d√≠a tiene 288 registros\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        # Resetear y ordenar por hora\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        # Crear DataFrame para el d√≠a actual\n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci√≥n_fotovoltaica_SFV': row_day_fronius['Producci√≥n_fotovoltaica_SFV'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "        })\n",
    "    \n",
    "        # Normalizar los datos de inter√©s\n",
    "        df_dia['Producci√≥n_fotovoltaica_SFV'] = scaler.fit_transform(df_dia[['Producci√≥n_fotovoltaica_SFV']])\n",
    "    \n",
    "        # Convertir la producci√≥n a tensor y cambiar forma\n",
    "        produccion_tensor = torch.tensor(df_dia['Producci√≥n_fotovoltaica_SFV'].values).view(1, -1, 1)\n",
    "        \n",
    "        # Agregar el tensor del d√≠a a la lista\n",
    "        tensors_SFV.append(produccion_tensor)\n",
    "        # Registrar la fecha en el diccionario de √≠ndices\n",
    "        indice_fechas_SFV[fecha] = len(tensors_SFV) - 1\n",
    "\n",
    "# Concatenar todos los tensores de d√≠as en un tensor [n, 288, 1]\n",
    "if tensors_SFV:\n",
    "    tensor_final = torch.cat(tensors_SFV, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, 1])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('../RNA/data_training/tensor_SFV.npy', tensor_final)\n",
    "    # Almacenar el mapeo de fechas a √≠ndices como JSON\n",
    "    with open('../RNA/data_training/indice_fechas_SFV.json', 'w') as fp:\n",
    "        json.dump(indice_fechas_SFV, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un tensor de entrada con segundo semestre de 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json \n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "# df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "# filtrar datos de solcast de 01/07/2023 a 31/12/2023\n",
    "df_solcast_2023_2 = df_solcast[df_solcast['Date'] >= '2023-07-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([185, 288, 3])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json \n",
    "\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "# filtrar datos de solcast de 01/07/2023 a 31/12/2023\n",
    "df_solcast_2023_2 = df_solcast[df_solcast['Date'] >= '2023-07-01']\n",
    "\n",
    "# Obtener fechas √∫nicas\n",
    "fechas_unicas = df_solcast_2023_2['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d√≠a\n",
    "tensors_dias = []\n",
    "# Diccionario para mapear fechas a √≠ndices en tensors_dias\n",
    "fechas_indices = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast.loc[df_solcast['Date'] == fecha]\n",
    "\n",
    "    # Verificar que el d√≠a tiene 288 registros\n",
    "    if len(row_day_solcast) == 288:\n",
    "        # Resetear y ordenar por hora\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "    \n",
    "        # Normalizar los datos de inter√©s\n",
    "        variables_normalizar = ['GHI', 'air_temp', 'cloud_opacity']\n",
    "        df_dia = row_day_solcast[variables_normalizar]\n",
    "        df_dia = scaler.fit_transform(df_dia)\n",
    "    \n",
    "        # Convertir a tensor y cambiar forma\n",
    "        dia_tensor = torch.tensor(df_dia).view(1, 288, -1)  # El tensor ya tiene forma [1, 288, n_variables]\n",
    "    \n",
    "        # Agregar el tensor del d√≠a a la lista\n",
    "        tensors_dias.append(dia_tensor)\n",
    "        # Agregar la fecha al diccionario\n",
    "        fechas_indices[fecha] = len(tensors_dias) - 1\n",
    "\n",
    "# Verificar si hay d√≠as para concatenar\n",
    "if tensors_dias:\n",
    "    # Concatenar todos los tensores de d√≠as en un tensor [n, 288, n_variables]\n",
    "    tensor_final = torch.cat(tensors_dias, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, n_variables])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('../RNA/data_training/input_tensor_2023-2.npy', tensor_final)\n",
    "    with open('../RNA/data_training/indice_fechas_input_2023-2.json', 'w') as fp:\n",
    "        json.dump(fechas_indices, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensores de entrada con fecha  üìÜ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json \n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# crear columna Date* a partir de la columna Date\n",
    "df_solcast ['Date*'] = df_solcast ['Date'] \n",
    "\n",
    "# quitar caracteres especiales y espacios\n",
    "df_solcast ['Date*'] = df_solcast ['Date*'].str.replace(' ', '')\n",
    "df_solcast ['Date*'] = df_solcast ['Date*'].str.replace('-', '')\n",
    "print(df_solcast ['Date*'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json \n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "# df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "# df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# Obtener fechas √∫nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d√≠a\n",
    "tensors_dias = []\n",
    "# Diccionario para mapear fechas a √≠ndices en tensors_dias\n",
    "fechas_indices = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast.loc[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV.loc[df_SFV['Date'] == fecha]\n",
    "\n",
    "    # Verificar que el d√≠a tiene 288 registros\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        # Procesamiento normal...\n",
    "        # Resetear y ordenar por hora\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        # Crear DataFrame para el d√≠a actual\n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci√≥n_fotovoltaica_SFV': row_day_fronius['Producci√≥n_fotovoltaica_SFV'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "            'date': row_day_solcast['Date*']\n",
    "        })\n",
    "    \n",
    "        # Normalizar los datos\n",
    "        df_dia[['GHI', 'Producci√≥n_fotovoltaica_SFV', 'clearsky_ghi', 'cloud_opacity', 'air_temp', 'date']] = scaler.fit_transform(df_dia[['GHI', 'Producci√≥n_fotovoltaica_SFV', 'clearsky_ghi', 'cloud_opacity', 'air_temp', 'date']])\n",
    "    \n",
    "        # Convertir a tensor y cambiar forma\n",
    "        ghi_tensor = torch.tensor(df_dia['GHI'].values).view(-1, 1)\n",
    "        air_temp_tensor = torch.tensor(df_dia['air_temp'].values).view(-1, 1)\n",
    "        cloud_opacity_tensor = torch.tensor(df_dia['cloud_opacity'].values).view(-1, 1)\n",
    "        date_tensor = torch.tensor(df_dia['date'].values).view(-1, 1)\n",
    "    \n",
    "        # Concatenar y cambiar forma a [1, 288, 3]\n",
    "        dia_tensor = torch.cat((ghi_tensor, air_temp_tensor, cloud_opacity_tensor, date_tensor), dim=1).unsqueeze(0)\n",
    "    \n",
    "        # Agregar el tensor del d√≠a a la lista\n",
    "        tensors_dias.append(dia_tensor)\n",
    "        # Agregar la fecha al diccionario\n",
    "        fechas_indices[fecha] = len(tensors_dias) - 1\n",
    "\n",
    "# Verificar si hay d√≠as para concatenar\n",
    "if tensors_dias:\n",
    "    # Concatenar todos los tensores de d√≠as en un tensor [n, 288, 3]\n",
    "    tensor_final = torch.cat(tensors_dias, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, 3])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('input_tensor.npy', tensor_final)\n",
    "    with open('indice_fechas_input.json', 'w') as fp:\n",
    "        json.dump(fechas_indices, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor SFV con fecha  üìÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# crear columna Date* a partir de la columna Date\n",
    "df_SFV ['Date**'] = df_SFV ['Date'] \n",
    "\n",
    "# quitar caracteres especiales y espacios\n",
    "df_SFV ['Date**'] = df_SFV ['Date**'].str.replace(' ', '')\n",
    "df_SFV ['Date**'] = df_SFV ['Date**'].str.replace('-', '')\n",
    "print(df_SFV ['Date**'])\n",
    "\n",
    "# Obtener fechas √∫nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d√≠a de la producci√≥n fotovoltaica\n",
    "tensors_SFV = []\n",
    "# Diccionario para mapear fechas a √≠ndices en tensors_SFV\n",
    "indice_fechas_SFV = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast.loc[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV.loc[df_SFV['Date'] == fecha]\n",
    "\n",
    "    # Verificar que el d√≠a tiene 288 registros\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        # Resetear y ordenar por hora\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        # Crear DataFrame para el d√≠a actual\n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci√≥n_fotovoltaica_SFV': row_day_fronius['Producci√≥n_fotovoltaica_SFV'],\n",
    "            'date': row_day_fronius['Date**'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "        })\n",
    "    \n",
    "        # Normalizar los datos de inter√©s\n",
    "        df_dia['Producci√≥n_fotovoltaica_SFV', 'date'] = scaler.fit_transform(df_dia[['Producci√≥n_fotovoltaica_SFV', 'date']])\n",
    "    \n",
    "        # Convertir la producci√≥n a tensor y cambiar forma\n",
    "        produccion_tensor = torch.tensor(df_dia['Producci√≥n_fotovoltaica_SFV', 'date'].values).view(1, -1, 1)\n",
    "        \n",
    "        # Agregar el tensor del d√≠a a la lista\n",
    "        tensors_SFV.append(produccion_tensor)\n",
    "        # Registrar la fecha en el diccionario de √≠ndices\n",
    "        indice_fechas_SFV[fecha] = len(tensors_SFV) - 1\n",
    "\n",
    "# Concatenar todos los tensores de d√≠as en un tensor [n, 288, 1]\n",
    "if tensors_SFV:\n",
    "    tensor_final = torch.cat(tensors_SFV, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, 1])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('tensor_SFV.npy', tensor_final)\n",
    "    # Almacenar el mapeo de fechas a √≠ndices como JSON\n",
    "    with open('indice_fechas_SFV.json', 'w') as fp:\n",
    "        json.dump(indice_fechas_SFV, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json  # Importa el m√≥dulo json para la serializaci√≥n\n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# crear columna Date** a partir de la columna Date\n",
    "df_SFV['Date**'] = df_SFV['Date'].str.replace(' ', '').replace('-', '', regex=True)\n",
    "\n",
    "# Obtener fechas √∫nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d√≠a de la producci√≥n fotovoltaica\n",
    "tensors_SFV = []\n",
    "\n",
    "# Diccionario para mapear fechas a √≠ndices en tensors_SFV\n",
    "indice_fechas_SFV = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV[df_SFV['Date'] == fecha]\n",
    "\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci√≥n_fotovoltaica_SFV': row_day_fronius['Producci√≥n_fotovoltaica_SFV'],\n",
    "            'date': row_day_fronius['Date**'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "        })\n",
    "        \n",
    "        # Normalizar los datos de inter√©s\n",
    "        normalized_values = scaler.fit_transform(df_dia[['Producci√≥n_fotovoltaica_SFV', 'date']])\n",
    "        df_dia[['Producci√≥n_fotovoltaica_SFV', 'date']] = normalized_values\n",
    "        \n",
    "        # Convertir la producci√≥n a tensor y cambiar forma\n",
    "        produccion_tensor = torch.tensor(normalized_values).view(1, -1, 2)  # Ajusta esta l√≠nea seg√∫n la estructura deseada\n",
    "        \n",
    "        tensors_SFV.append(produccion_tensor)\n",
    "        indice_fechas_SFV[fecha] = len(tensors_SFV) - 1\n",
    "\n",
    "# Concatenar todos los tensores de d√≠as en un tensor [n, 288, 1]\n",
    "if tensors_SFV:\n",
    "    tensor_final = torch.cat(tensors_SFV, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, 1])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('tensor_SFV.npy', tensor_final)\n",
    "    # Almacenar el mapeo de fechas a √≠ndices como JSON\n",
    "    with open('indice_fechas_SFV.json', 'w') as fp:\n",
    "        json.dump(indice_fechas_SFV, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ******************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor de entrada Dividido ‚úÇÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json \n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# Obtener fechas √∫nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d√≠a\n",
    "tensors_dias = []\n",
    "# Diccionario para mapear fechas a √≠ndices en tensors_dias\n",
    "fechas_indices = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast.loc[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV.loc[df_SFV['Date'] == fecha]\n",
    "\n",
    "    # Verificar que el d√≠a tiene 288 registros\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        # Procesamiento normal...\n",
    "        # Resetear y ordenar por hora\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        # Crear DataFrame para el d√≠a actual\n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci√≥n_fotovoltaica_SFV': row_day_fronius['Producci√≥n_fotovoltaica_SFV'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "        })\n",
    "    \n",
    "        # Normalizar los datos\n",
    "        df_dia[['GHI', 'Producci√≥n_fotovoltaica_SFV', 'clearsky_ghi', 'cloud_opacity', 'air_temp']] = scaler.fit_transform(df_dia[['GHI', 'Producci√≥n_fotovoltaica_SFV', 'clearsky_ghi', 'cloud_opacity', 'air_temp']])\n",
    "    \n",
    "        # Convertir a tensor y cambiar forma\n",
    "        ghi_tensor = torch.tensor(df_dia['GHI'].values).view(-1, 1)\n",
    "        air_temp_tensor = torch.tensor(df_dia['air_temp'].values).view(-1, 1)\n",
    "        cloud_opacity_tensor = torch.tensor(df_dia['cloud_opacity'].values).view(-1, 1)\n",
    "    \n",
    "        # Concatenar y cambiar forma a [1, 288, 3]\n",
    "        dia_tensor = torch.cat((ghi_tensor, air_temp_tensor, cloud_opacity_tensor), dim=1).unsqueeze(0)\n",
    "    \n",
    "        # Agregar el tensor del d√≠a a la lista\n",
    "        tensors_dias.append(dia_tensor)\n",
    "        # Agregar la fecha al diccionario\n",
    "        fechas_indices[fecha] = len(tensors_dias) - 1\n",
    "\n",
    "# Verificar si hay d√≠as para concatenar\n",
    "if tensors_dias:\n",
    "    # Concatenar todos los tensores de d√≠as en un tensor [n, 288, 3]\n",
    "    tensor_final = torch.cat(tensors_dias, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, 3])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('all_input_tensor.npy', tensor_final)\n",
    "    with open('indice_fechas_all_input.json', 'w') as fp:\n",
    "        json.dump(fechas_indices, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba 90-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Calcular el tama√±o de los datos de entrenamiento y test\n",
    "num_datos = tensor_final.size(0)  # N√∫mero total de d√≠as\n",
    "num_entrenamiento = int(num_datos * 0.9)  # El 90% de los datos\n",
    "\n",
    "# Dividir los tensores\n",
    "tensor_entrada_entrenamiento = tensor_final[:num_entrenamiento]  # Los primeros 90%\n",
    "tensor_entrada_test = tensor_final[num_entrenamiento:]  # El resto (10%)\n",
    "\n",
    "print(tensor_entrada_entrenamiento.shape)  # Salida esperada: torch.Size([n*0.9, 288, 3])\n",
    "print(tensor_entrada_test.shape)  # Salida esperada: torch.Size([n*0.1, 288, 3])\n",
    "\n",
    "# Almacenar el tensor en un archivo\n",
    "np.save('../RNA/data_training/tensor_entrada_entrenamiento.npy', tensor_entrada_entrenamiento)\n",
    "np.save('../RNA/data_training/tensor_entrada_test.npy', tensor_entrada_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregar un diccionario con los indices para cada fecha "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisi√≥n 8 de abril \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "# Cargar los datos\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "tensors_dias = []\n",
    "fechas_indices = {}\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV[df_SFV['Date'] == fecha]\n",
    "\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "\n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci√≥n_fotovoltaica_SFV': row_day_fronius['Producci√≥n_fotovoltaica_SFV'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "        })\n",
    "\n",
    "        df_dia[['GHI', 'Producci√≥n_fotovoltaica_SFV', 'clearsky_ghi', 'cloud_opacity', 'air_temp']] = scaler.fit_transform(df_dia[['GHI', 'Producci√≥n_fotovoltaica_SFV', 'clearsky_ghi', 'cloud_opacity', 'air_temp']])\n",
    "\n",
    "        ghi_tensor = torch.tensor(df_dia['GHI'].values).view(-1, 1)\n",
    "        air_temp_tensor = torch.tensor(df_dia['air_temp'].values).view(-1, 1)\n",
    "        cloud_opacity_tensor = torch.tensor(df_dia['cloud_opacity'].values).view(-1, 1)\n",
    "\n",
    "        dia_tensor = torch.cat((ghi_tensor, air_temp_tensor, cloud_opacity_tensor), dim=1).unsqueeze(0)\n",
    "\n",
    "        tensors_dias.append(dia_tensor)\n",
    "        fechas_indices[fecha] = len(tensors_dias) - 1\n",
    "\n",
    "if tensors_dias:\n",
    "    tensor_final = torch.cat(tensors_dias, dim=0)\n",
    "    \n",
    "    # Generar √≠ndices aleatorios y dividir\n",
    "    indices = np.arange(tensor_final.size(0))\n",
    "    indices_entrenamiento, indices_pruebas = train_test_split(indices, test_size=0.1, random_state=42)\n",
    "    \n",
    "    tensor_entrenamiento = tensor_final[indices_entrenamiento]\n",
    "    tensor_pruebas = tensor_final[indices_pruebas]\n",
    "    \n",
    "    fechas_entrenamiento = {fecha: i for i, fecha in enumerate(fechas_indices.keys()) if i in indices_entrenamiento}\n",
    "    fechas_pruebas = {fecha: i for i, fecha in enumerate(fechas_indices.keys()) if i in indices_pruebas}\n",
    "    \n",
    "    np.save('../RNA/data_training/tensor_entrenamiento.npy', tensor_entrenamiento)\n",
    "    np.save('../RNA/data_test/tensor_pruebas.npy', tensor_pruebas)\n",
    "    \n",
    "    with open('../RNA/data_training/indice_fechas_entrenamiento.json', 'w') as fp:\n",
    "        json.dump(fechas_entrenamiento, fp)\n",
    "    \n",
    "    with open('../RNA/data_test/indice_fechas_pruebas.json', 'w') as fp:\n",
    "        json.dump(fechas_pruebas, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor SFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# Obtener fechas √∫nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d√≠a de la producci√≥n fotovoltaica\n",
    "tensors_SFV = []\n",
    "# Diccionario para mapear fechas a √≠ndices en tensors_SFV\n",
    "indice_fechas_SFV = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast.loc[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV.loc[df_SFV['Date'] == fecha]\n",
    "\n",
    "    # Verificar que el d√≠a tiene 288 registros\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        # Resetear y ordenar por hora\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        # Crear DataFrame para el d√≠a actual\n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci√≥n_fotovoltaica_SFV': row_day_fronius['Producci√≥n_fotovoltaica_SFV'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "        })\n",
    "    \n",
    "        # Normalizar los datos de inter√©s\n",
    "        df_dia['Producci√≥n_fotovoltaica_SFV'] = scaler.fit_transform(df_dia[['Producci√≥n_fotovoltaica_SFV']])\n",
    "    \n",
    "        # Convertir la producci√≥n a tensor y cambiar forma\n",
    "        produccion_tensor = torch.tensor(df_dia['Producci√≥n_fotovoltaica_SFV'].values).view(1, -1, 1)\n",
    "        \n",
    "        # Agregar el tensor del d√≠a a la lista\n",
    "        tensors_SFV.append(produccion_tensor)\n",
    "        # Registrar la fecha en el diccionario de √≠ndices\n",
    "        indice_fechas_SFV[fecha] = len(tensors_SFV) - 1\n",
    "\n",
    "# Concatenar todos los tensores de d√≠as en un tensor [n, 288, 1]\n",
    "if tensors_SFV:\n",
    "    tensor_final = torch.cat(tensors_SFV, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, 1])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('tensor_SFV.npy', tensor_final)\n",
    "    # Almacenar el mapeo de fechas a √≠ndices como JSON\n",
    "    with open('indice_fechas_SFV.json', 'w') as fp:\n",
    "        json.dump(indice_fechas_SFV, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# Obtener fechas √∫nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d√≠a de la producci√≥n fotovoltaica\n",
    "tensors_SFV = []\n",
    "# Diccionario para mapear fechas a √≠ndices en tensors_SFV\n",
    "indice_fechas_SFV = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast.loc[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV.loc[df_SFV['Date'] == fecha]\n",
    "\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci√≥n_fotovoltaica_SFV': row_day_fronius['Producci√≥n_fotovoltaica_SFV'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "        })\n",
    "    \n",
    "        df_dia['Producci√≥n_fotovoltaica_SFV'] = scaler.fit_transform(df_dia[['Producci√≥n_fotovoltaica_SFV']])\n",
    "    \n",
    "        produccion_tensor = torch.tensor(df_dia['Producci√≥n_fotovoltaica_SFV'].values).view(1, -1, 1)\n",
    "        \n",
    "        tensors_SFV.append(produccion_tensor)\n",
    "        indice_fechas_SFV[fecha] = len(tensors_SFV) - 1\n",
    "\n",
    "if tensors_SFV:\n",
    "    tensor_final = torch.cat(tensors_SFV, dim=0)\n",
    "    \n",
    "    # Generar √≠ndices aleatorios y dividir\n",
    "    indices = np.arange(tensor_final.size(0))\n",
    "    indices_entrenamiento, indices_pruebas = train_test_split(indices, test_size=0.1, random_state=42)\n",
    "    \n",
    "    tensor_entrenamiento_SFV = tensor_final[indices_entrenamiento]\n",
    "    tensor_pruebas_SFV = tensor_final[indices_pruebas]\n",
    "    \n",
    "    # Extraer fechas correspondientes a los √≠ndices de entrenamiento y pruebas\n",
    "    fechas_entrenamiento_SFV = {fecha: i for i, fecha in enumerate(indice_fechas_SFV.keys()) if indice_fechas_SFV[fecha] in indices_entrenamiento}\n",
    "    fechas_pruebas_SFV = {fecha: i for i, fecha in enumerate(indice_fechas_SFV.keys()) if indice_fechas_SFV[fecha] in indices_pruebas}\n",
    "    \n",
    "    # Guardar los tensores y los √≠ndices de las fechas\n",
    "    np.save('../RNA/data_training/tensor_entrenamiento_SFV.npy', tensor_entrenamiento_SFV)\n",
    "    np.save('../RNA/data_test/tensor_pruebas_SFV.npy', tensor_pruebas_SFV)\n",
    "    \n",
    "    with open('../RNA/data_training/indice_fechas_entrenamiento_SFV.json', 'w') as fp:\n",
    "        json.dump(fechas_entrenamiento_SFV, fp)\n",
    "    \n",
    "    with open('../RNA/data_test/indice_fechas_pruebas_SFV.json', 'w') as fp:\n",
    "        json.dump(fechas_pruebas_SFV, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
