{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([180, 288, 3])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json \n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# Obtener fechas 칰nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d칤a\n",
    "tensors_dias = []\n",
    "# Diccionario para mapear fechas a 칤ndices en tensors_dias\n",
    "fechas_indices = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast.loc[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV.loc[df_SFV['Date'] == fecha]\n",
    "\n",
    "    # Verificar que el d칤a tiene 288 registros\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        # Procesamiento normal...\n",
    "        # Resetear y ordenar por hora\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        # Crear DataFrame para el d칤a actual\n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci칩n_fotovoltaica_SFV': row_day_fronius['Producci칩n_fotovoltaica_SFV'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "        })\n",
    "    \n",
    "        # Normalizar los datos\n",
    "        df_dia[['GHI', 'Producci칩n_fotovoltaica_SFV', 'clearsky_ghi', 'cloud_opacity', 'air_temp']] = scaler.fit_transform(df_dia[['GHI', 'Producci칩n_fotovoltaica_SFV', 'clearsky_ghi', 'cloud_opacity', 'air_temp']])\n",
    "    \n",
    "        # Convertir a tensor y cambiar forma\n",
    "        ghi_tensor = torch.tensor(df_dia['GHI'].values).view(-1, 1)\n",
    "        air_temp_tensor = torch.tensor(df_dia['air_temp'].values).view(-1, 1)\n",
    "        cloud_opacity_tensor = torch.tensor(df_dia['cloud_opacity'].values).view(-1, 1)\n",
    "    \n",
    "        # Concatenar y cambiar forma a [1, 288, 3]\n",
    "        dia_tensor = torch.cat((ghi_tensor, air_temp_tensor, cloud_opacity_tensor), dim=1).unsqueeze(0)\n",
    "    \n",
    "        # Agregar el tensor del d칤a a la lista\n",
    "        tensors_dias.append(dia_tensor)\n",
    "        # Agregar la fecha al diccionario\n",
    "        fechas_indices[fecha] = len(tensors_dias) - 1\n",
    "\n",
    "# Verificar si hay d칤as para concatenar\n",
    "if tensors_dias:\n",
    "    # Concatenar todos los tensores de d칤as en un tensor [n, 288, 3]\n",
    "    tensor_final = torch.cat(tensors_dias, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, 3])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('input_tensor.npy', tensor_final)\n",
    "    with open('indice_fechas_input.json', 'w') as fp:\n",
    "        json.dump(fechas_indices, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor SFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([180, 288, 1])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# Obtener fechas 칰nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d칤a de la producci칩n fotovoltaica\n",
    "tensors_SFV = []\n",
    "# Diccionario para mapear fechas a 칤ndices en tensors_SFV\n",
    "indice_fechas_SFV = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast.loc[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV.loc[df_SFV['Date'] == fecha]\n",
    "\n",
    "    # Verificar que el d칤a tiene 288 registros\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        # Resetear y ordenar por hora\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        # Crear DataFrame para el d칤a actual\n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci칩n_fotovoltaica_SFV': row_day_fronius['Producci칩n_fotovoltaica_SFV'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "        })\n",
    "    \n",
    "        # Normalizar los datos de inter칠s\n",
    "        df_dia['Producci칩n_fotovoltaica_SFV'] = scaler.fit_transform(df_dia[['Producci칩n_fotovoltaica_SFV']])\n",
    "    \n",
    "        # Convertir la producci칩n a tensor y cambiar forma\n",
    "        produccion_tensor = torch.tensor(df_dia['Producci칩n_fotovoltaica_SFV'].values).view(1, -1, 1)\n",
    "        \n",
    "        # Agregar el tensor del d칤a a la lista\n",
    "        tensors_SFV.append(produccion_tensor)\n",
    "        # Registrar la fecha en el diccionario de 칤ndices\n",
    "        indice_fechas_SFV[fecha] = len(tensors_SFV) - 1\n",
    "\n",
    "# Concatenar todos los tensores de d칤as en un tensor [n, 288, 1]\n",
    "if tensors_SFV:\n",
    "    tensor_final = torch.cat(tensors_SFV, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, 1])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('tensor_SFV.npy', tensor_final)\n",
    "    # Almacenar el mapeo de fechas a 칤ndices como JSON\n",
    "    with open('indice_fechas_SFV.json', 'w') as fp:\n",
    "        json.dump(indice_fechas_SFV, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensores con fecha  游늱\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         20230101\n",
      "1         20230101\n",
      "2         20230101\n",
      "3         20230101\n",
      "4         20230101\n",
      "            ...   \n",
      "105403    20240101\n",
      "105404    20240101\n",
      "105405    20240101\n",
      "105406    20240101\n",
      "105407    20240102\n",
      "Name: Date*, Length: 105408, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json \n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# crear columna Date* a partir de la columna Date\n",
    "df_solcast ['Date*'] = df_solcast ['Date'] \n",
    "\n",
    "# quitar caracteres especiales y espacios\n",
    "df_solcast ['Date*'] = df_solcast ['Date*'].str.replace(' ', '')\n",
    "df_solcast ['Date*'] = df_solcast ['Date*'].str.replace('-', '')\n",
    "print(df_solcast ['Date*'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([180, 288, 4])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json \n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "# df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "# df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# Obtener fechas 칰nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d칤a\n",
    "tensors_dias = []\n",
    "# Diccionario para mapear fechas a 칤ndices en tensors_dias\n",
    "fechas_indices = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast.loc[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV.loc[df_SFV['Date'] == fecha]\n",
    "\n",
    "    # Verificar que el d칤a tiene 288 registros\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        # Procesamiento normal...\n",
    "        # Resetear y ordenar por hora\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        # Crear DataFrame para el d칤a actual\n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci칩n_fotovoltaica_SFV': row_day_fronius['Producci칩n_fotovoltaica_SFV'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "            'date': row_day_solcast['Date*']\n",
    "        })\n",
    "    \n",
    "        # Normalizar los datos\n",
    "        df_dia[['GHI', 'Producci칩n_fotovoltaica_SFV', 'clearsky_ghi', 'cloud_opacity', 'air_temp', 'date']] = scaler.fit_transform(df_dia[['GHI', 'Producci칩n_fotovoltaica_SFV', 'clearsky_ghi', 'cloud_opacity', 'air_temp', 'date']])\n",
    "    \n",
    "        # Convertir a tensor y cambiar forma\n",
    "        ghi_tensor = torch.tensor(df_dia['GHI'].values).view(-1, 1)\n",
    "        air_temp_tensor = torch.tensor(df_dia['air_temp'].values).view(-1, 1)\n",
    "        cloud_opacity_tensor = torch.tensor(df_dia['cloud_opacity'].values).view(-1, 1)\n",
    "        date_tensor = torch.tensor(df_dia['date'].values).view(-1, 1)\n",
    "    \n",
    "        # Concatenar y cambiar forma a [1, 288, 3]\n",
    "        dia_tensor = torch.cat((ghi_tensor, air_temp_tensor, cloud_opacity_tensor, date_tensor), dim=1).unsqueeze(0)\n",
    "    \n",
    "        # Agregar el tensor del d칤a a la lista\n",
    "        tensors_dias.append(dia_tensor)\n",
    "        # Agregar la fecha al diccionario\n",
    "        fechas_indices[fecha] = len(tensors_dias) - 1\n",
    "\n",
    "# Verificar si hay d칤as para concatenar\n",
    "if tensors_dias:\n",
    "    # Concatenar todos los tensores de d칤as en un tensor [n, 288, 3]\n",
    "    tensor_final = torch.cat(tensors_dias, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, 3])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('input_tensor.npy', tensor_final)\n",
    "    with open('indice_fechas_input.json', 'w') as fp:\n",
    "        json.dump(fechas_indices, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor SFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        20230101\n",
      "1        20230101\n",
      "2        20230101\n",
      "3        20230101\n",
      "4        20230101\n",
      "           ...   \n",
      "52123    20230630\n",
      "52124    20230630\n",
      "52125    20230630\n",
      "52126    20230630\n",
      "52127    20230630\n",
      "Name: Date**, Length: 52128, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected a 1D array, got an array with shape (288, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('Producci칩n_fotovoltaica_SFV', 'date')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pandas/core/frame.py:4473\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value, refs)\u001b[0m\n\u001b[1;32m   4472\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4473\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4474\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   4475\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('Producci칩n_fotovoltaica_SFV', 'date')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 51\u001b[0m\n\u001b[1;32m     40\u001b[0m df_dia \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m: row_day_solcast[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGHI\u001b[39m\u001b[38;5;124m'\u001b[39m: row_day_solcast[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGHI\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclearsky_ghi\u001b[39m\u001b[38;5;124m'\u001b[39m: row_day_solcast[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclearsky_ghi\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     48\u001b[0m })\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Normalizar los datos de inter칠s\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mdf_dia\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProducci칩n_fotovoltaica_SFV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(df_dia[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProducci칩n_fotovoltaica_SFV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Convertir la producci칩n a tensor y cambiar forma\u001b[39;00m\n\u001b[1;32m     54\u001b[0m produccion_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(df_dia[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProducci칩n_fotovoltaica_SFV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pandas/core/frame.py:4299\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4298\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pandas/core/frame.py:4526\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4523\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   4524\u001b[0m             refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 4526\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pandas/core/frame.py:4476\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value, refs)\u001b[0m\n\u001b[1;32m   4473\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4474\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   4475\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[0;32m-> 4476\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4478\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_item_mgr(loc, value, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pandas/core/internals/managers.py:1370\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[0;34m(self, loc, item, value, refs)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1370\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1371\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a 1D array, got an array with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1372\u001b[0m         )\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     value \u001b[38;5;241m=\u001b[39m ensure_block_shape(value, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a 1D array, got an array with shape (288, 2)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# crear columna Date* a partir de la columna Date\n",
    "df_SFV ['Date**'] = df_SFV ['Date'] \n",
    "\n",
    "# quitar caracteres especiales y espacios\n",
    "df_SFV ['Date**'] = df_SFV ['Date**'].str.replace(' ', '')\n",
    "df_SFV ['Date**'] = df_SFV ['Date**'].str.replace('-', '')\n",
    "print(df_SFV ['Date**'])\n",
    "\n",
    "# Obtener fechas 칰nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d칤a de la producci칩n fotovoltaica\n",
    "tensors_SFV = []\n",
    "# Diccionario para mapear fechas a 칤ndices en tensors_SFV\n",
    "indice_fechas_SFV = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast.loc[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV.loc[df_SFV['Date'] == fecha]\n",
    "\n",
    "    # Verificar que el d칤a tiene 288 registros\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        # Resetear y ordenar por hora\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        # Crear DataFrame para el d칤a actual\n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci칩n_fotovoltaica_SFV': row_day_fronius['Producci칩n_fotovoltaica_SFV'],\n",
    "            'date': row_day_fronius['Date**'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "        })\n",
    "    \n",
    "        # Normalizar los datos de inter칠s\n",
    "        df_dia['Producci칩n_fotovoltaica_SFV', 'date'] = scaler.fit_transform(df_dia[['Producci칩n_fotovoltaica_SFV', 'date']])\n",
    "    \n",
    "        # Convertir la producci칩n a tensor y cambiar forma\n",
    "        produccion_tensor = torch.tensor(df_dia['Producci칩n_fotovoltaica_SFV', 'date'].values).view(1, -1, 1)\n",
    "        \n",
    "        # Agregar el tensor del d칤a a la lista\n",
    "        tensors_SFV.append(produccion_tensor)\n",
    "        # Registrar la fecha en el diccionario de 칤ndices\n",
    "        indice_fechas_SFV[fecha] = len(tensors_SFV) - 1\n",
    "\n",
    "# Concatenar todos los tensores de d칤as en un tensor [n, 288, 1]\n",
    "if tensors_SFV:\n",
    "    tensor_final = torch.cat(tensors_SFV, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, 1])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('tensor_SFV.npy', tensor_final)\n",
    "    # Almacenar el mapeo de fechas a 칤ndices como JSON\n",
    "    with open('indice_fechas_SFV.json', 'w') as fp:\n",
    "        json.dump(indice_fechas_SFV, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([180, 288, 2])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json  # Importa el m칩dulo json para la serializaci칩n\n",
    "\n",
    "# Cargar los datos del archivo CSV\n",
    "df_SFV = pd.read_csv('../Data/Cleaned/SFV_2023.csv', sep=',')\n",
    "df_solcast = pd.read_csv('../Data/Cleaned/solcast_2023.csv', sep=',')\n",
    "\n",
    "# crear columna Date** a partir de la columna Date\n",
    "df_SFV['Date**'] = df_SFV['Date'].str.replace(' ', '').replace('-', '', regex=True)\n",
    "\n",
    "# Obtener fechas 칰nicas\n",
    "fechas_unicas = df_solcast['Date'].unique()\n",
    "\n",
    "# Lista para guardar los tensores de cada d칤a de la producci칩n fotovoltaica\n",
    "tensors_SFV = []\n",
    "\n",
    "# Diccionario para mapear fechas a 칤ndices en tensors_SFV\n",
    "indice_fechas_SFV = {}\n",
    "\n",
    "# Escalador MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for fecha in fechas_unicas:\n",
    "    row_day_solcast = df_solcast[df_solcast['Date'] == fecha]\n",
    "    row_day_fronius = df_SFV[df_SFV['Date'] == fecha]\n",
    "\n",
    "    if len(row_day_solcast) == 288 and len(row_day_fronius) == 288:\n",
    "        row_day_solcast = row_day_solcast.sort_values(by='Time').reset_index(drop=True)\n",
    "        row_day_fronius = row_day_fronius.reset_index(drop=True)\n",
    "    \n",
    "        df_dia = pd.DataFrame({\n",
    "            'Time': row_day_solcast['Time'],\n",
    "            'GHI': row_day_solcast['GHI'],\n",
    "            'air_temp': row_day_solcast['air_temp'],\n",
    "            'cloud_opacity': row_day_solcast['cloud_opacity'],\n",
    "            'Producci칩n_fotovoltaica_SFV': row_day_fronius['Producci칩n_fotovoltaica_SFV'],\n",
    "            'date': row_day_fronius['Date**'],\n",
    "            'clearsky_ghi': row_day_solcast['clearsky_ghi'],\n",
    "        })\n",
    "        \n",
    "        # Normalizar los datos de inter칠s\n",
    "        normalized_values = scaler.fit_transform(df_dia[['Producci칩n_fotovoltaica_SFV', 'date']])\n",
    "        df_dia[['Producci칩n_fotovoltaica_SFV', 'date']] = normalized_values\n",
    "        \n",
    "        # Convertir la producci칩n a tensor y cambiar forma\n",
    "        produccion_tensor = torch.tensor(normalized_values).view(1, -1, 2)  # Ajusta esta l칤nea seg칰n la estructura deseada\n",
    "        \n",
    "        tensors_SFV.append(produccion_tensor)\n",
    "        indice_fechas_SFV[fecha] = len(tensors_SFV) - 1\n",
    "\n",
    "# Concatenar todos los tensores de d칤as en un tensor [n, 288, 1]\n",
    "if tensors_SFV:\n",
    "    tensor_final = torch.cat(tensors_SFV, dim=0)\n",
    "    print(tensor_final.shape)  # Salida esperada: torch.Size([n, 288, 1])\n",
    "    # Almacenar el tensor en un archivo\n",
    "    np.save('tensor_SFV.npy', tensor_final)\n",
    "    # Almacenar el mapeo de fechas a 칤ndices como JSON\n",
    "    with open('indice_fechas_SFV.json', 'w') as fp:\n",
    "        json.dump(indice_fechas_SFV, fp)\n",
    "else:\n",
    "    print(\"No hay suficientes datos para crear el tensor final.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
